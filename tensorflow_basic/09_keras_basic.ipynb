{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d724ad0-fc8c-4d52-a67f-26cfa6d71b1c",
   "metadata": {},
   "source": [
    "# Keras Basic\n",
    "### * Sequential Layer 의 주요 레이어 정리 \n",
    "#### [1]  Dense Layer : Fully Connected Layer, layer의 입력과 출력 사이에 있는 모든 뉴런이 서로 연결 되는 Layer\n",
    "#### [2]  Flatten Layer : 다차원(4차원)을 2차원으로 축소하여 FC Layer에 전달한다\n",
    "#### [3]  Conv2D Layer : 이미지 특징을 추출하는 Convolution Layer \n",
    "#### [4]  MaxPool2D Layer : 중요 데이터(값이 큰 데이터)를 subsampling 하는 Layer\n",
    "#### [5]  Dropout Layer : 학습시 신경망의 과적합을 막기위해 일부 뉴런을 제거하는 Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30a0a7-aa9e-4ba2-b565-1177cfdba8e3",
   "metadata": {},
   "source": [
    "## [1] Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15629911-73be-41af-9a49-55a6dbc2be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab29058b-8b5f-45d5-bfe9-ddd93c569b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras를 이용한 XOR 네트워크\n",
    "# train data set \n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]   # (4,2)\n",
    "\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]     # (4,1)\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa1a0e7-c292-453d-a549-a9dfa9a9fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense Layer 구현\n",
    "model = tf.keras.Sequential([\n",
    "    # (4,2)*(2,4) = (4,4)\n",
    "    tf.keras.layers.Dense(units=4, activation='relu', input_shape=(2,) ),\n",
    "    \n",
    "    # (4,4)*(4,1) = (4,1)\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0953f0-d3d0-4cd2-b9d5-7a4ba9b34617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27383061b40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=1,verbose=1) # verbose = 1 => 메시지출력 (생략가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aeafd4b-b7be-4cd9-8f5d-9cdb10ead61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(x_train)\n",
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9ee33f-6b01-4c9d-8e57-d2e3b8b18c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4525 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4525080919265747, 0.75]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c670a-5d3b-499d-acb7-fef8f52f91d3",
   "metadata": {},
   "source": [
    "## [2] Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7647ec3-4d2a-422e-bd21-e922b6aa61d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 10)\n",
      "(1000, 7840)\n"
     ]
    }
   ],
   "source": [
    "# 4차원 데이터를 2차원으로 축소하여 FC Layer에 전달\n",
    "data = np.arange(1000*28*28*10).reshape(1000,28,28,10).astype(np.float32)\n",
    "print(data.shape)   # (None,28,28,10)\n",
    "\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape)    # (None, 28*28*10) = (None,7840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef5803c-f0dd-4eb9-a050-0b06a694660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 3차원 데이터를 2차원으로 축소하여 FC Layer에 전달\n",
    "data = np.arange(1000*28*28).reshape(1000,28,28).astype(np.float32)\n",
    "print(data.shape)   # (None,28,28)\n",
    "\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape)    # (None, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6daa48-ed4f-48f0-8518-95bf61cd23e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 데이터를 2차원으로 축소하여 FC Layer에 전달\n",
    "data = np.arange(28*28).reshape(28,28).astype(np.float32)\n",
    "print(data.shape)   # (28,28)\n",
    "\n",
    "layer = tf.keras.layers.Flatten()\n",
    "outputs = layer(data)\n",
    "print(outputs.shape)    # (28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca87df-1565-4a85-b0df-9e7dc160b382",
   "metadata": {},
   "source": [
    "## [3] Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e21ddc31-fc61-473a-a264-b9b4e40d2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "### The Dropout layer randomly sets input units to 0 with a frequency of rate \n",
    "### at each step during training time, which helps prevent overfitting. \n",
    "### Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "\n",
    "### Note that the Dropout layer only applies when training is set to True such that\n",
    "### no values are dropped during inference. When using model.fit, training will be\n",
    "### appropriately set\n",
    "\n",
    "### not set to 0 are scaled up by 1/(1-rate)\n",
    "### trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4680ada7-c650-4cb9-8cf3-1c8be26adaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]\n",
      " [6. 7.]\n",
      " [8. 9.]]\n",
      "tf.Tensor(\n",
      "[[ 0.         0.       ]\n",
      " [ 2.857143   4.285714 ]\n",
      " [ 5.714286   7.1428576]\n",
      " [ 8.571428  10.       ]\n",
      " [11.428572   0.       ]], shape=(5, 2), dtype=float32)\n",
      "[[ 0.         1.4285715]\n",
      " [ 2.857143   4.285714 ]\n",
      " [ 5.714286   7.142857 ]\n",
      " [ 8.571428  10.       ]\n",
      " [11.428572  12.857143 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "data = np.arange(10).reshape(5,2).astype(np.float32)\n",
    "print(data)\n",
    "\n",
    "layer = tf.keras.layers.Dropout(0.3,input_shape=(2,))\n",
    "\n",
    "outputs = layer(data,training=True)\n",
    "# model.fit()호출 시는  학습 모드로 training=True가 되어 dropuout 적용\n",
    "# model.evaluate() 호출 시는 예측 모드로 False가 되어 dropuout이 수행되지 않음\n",
    "print(outputs) # 데이터의 30%는 0으로 나머지 데이터는  1/(1-0.3)으로 곱하여 scaled up된다\n",
    "print(data*1/(1 - 0.3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
